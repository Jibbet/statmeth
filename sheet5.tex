\section{Sheet}
\subsection{Bernoulli}
\subsubsection{Clopper and Pearson confidence interval}
A Bernoulli experiment is repeated $n=200$ times with $k=121$ sucesses. Calculate the symmetric $95\%$ interval
for the  parameter $p$.
The Interval boundaries can be calculated with the inverse beta distribution.
\begin{align}
    G_1\left(k\right)&=\beta\left(\frac{\alpha}{2};k,n-k+1\right)=0.534
    \\G_2\left(k\right)&=\beta\left(\frac{1-\alpha}{2};k+1,n-k\right)=0.673
\end{align}
\subsubsection{Approximation by normal distribution (bootstrap and robust)}
Estimate $p$:
\begin{equation}
    \hat{p}=\frac{k}{n}=\frac{121}{200}
\end{equation}
With that estimate $\sigma$
\begin{align}
    \sigma\left[\hat{p}\right]&=\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}
    \\&=\sqrt{\frac{9559}{8\cdot 10^6}}\approx 0.035
\end{align}
\begin{equation}
    z_{1-\frac{\alpha}{2}}=f_{\text{norm}}\left(1-\frac{\alpha}{2}\right)=0.248
\end{equation}
Now the interval boundaries are for the bootstrap method:
\begin{align}
    G_1\left(k\right)&=\hat{p}-z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\approx 0.591
    \\G_1\left(k\right)&=\hat{p}+z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\approx 0.619
\end{align}
and for the robust method
\begin{align}
    G_1\left(k\right)&=\hat{p}-z_{1-\frac{\alpha}{2}}\frac{1}{2\sqrt{n}}\approx 0.585
    \\G_1\left(k\right)&=\hat{p}+z_{1-\frac{\alpha}{2}}\frac{1}{2\sqrt{n}}\approx 0.625
\end{align}
\subsubsection{Agresti-Coull}
\begin{align}
    G_1\left(k\right)\approx 0.585
    \\G_2\left(k\right)\approx 0.624
\end{align}
\subsection{Biased and unbiased Estimators for uniform distribution interval borders}
The joint probability of the sample ist
\begin{equation}
    g\left(X_1,\dots,X_N\vert a,b\right)=\prod_n^N \frac{1}{b-a}\cdot I_{\left[a,b\right]}\left(X_n\right)
\end{equation}
The ML estimator is
\begin{equation}
    \hat{a}=\text{arg max}_a\prod_{n}^{N}\frac{1}{b-a}\cdot I_{\left[a,b\right]}\left(X_n\right)
\end{equation}
This would not take a minimum if not for the constraint
\begin{equation}
    \hat{a}\leq\min_n\left\{X_n\right\}
\end{equation}
Therefore
\begin{equation}
    \hat{a}=\min_n\left\{X_n\right\}
\end{equation}
Similarly
\begin{equation}
    \hat{b}\geq\max_n\left\{X_n\right\}
\end{equation}
and
\begin{equation}
    \hat{b}=\max_n\left\{X_n\right\}
\end{equation}
\paragraph{Showing the estimators are biased}
To show the estimators are biased, calculate their distribution functions:
\begin{align}
    F_{\hat{a}}\left(x\right)=P\left(\hat{a}\leq x\right)&=1-\prod_n P\left(X_n>x\right)
    \\&=1-P^N\left(X>x\right)
    \\&=1-\left(\frac{b-x}{b-a}\right)^N
\end{align}
The density is
\begin{align}
    \pdv{F_{\hat{a}}}{x}&=\frac{N}{b-a}\left(\frac{b-x}{b-a}\right)^{N-1}
\end{align}
Now the expectation value is
\begin{align}
    E\left(\hat{a}\right)&=\int_a^b x \frac{n}{b-a}\left(\frac{b-x}{b-a}\right)^{N-1}\;dx
    \\&=\left[-\left(\frac{b-x}{b-a}\right)^N x\right]_a^b+\int_a^b\left(\frac{b-x}{b-a}\right)^N\;dx
\end{align}
Here is
\begin{align}
    \left[-\left(\frac{b-x}{b-a}\right)^N x\right]_a^b=\left[-\underbrace{\left(\frac{b-b}{b-a}\right)^N}_{=0}b + \underbrace{\left(\frac{b-a}{b-a}\right)^N}_{=1}a\right]=a
\end{align}
and
\begin{align}
    \int_a^b\left(\frac{b-x}{b-a}\right)^N\;dx&=\left[-\frac{b-a}{N+1}\left(\frac{b-x}{b-a}\right)^{N+1}\right]_a^b
    \\&=-\frac{b-a}{N+1}\left[\underbrace{\left(\frac{b-b}{b-a}\right)^{N+1}}_{=0}-\underbrace{\left(\frac{b-a}{b-a}\right)^{N+1}}_{=1}\right]
    \\&=\frac{b-a}{N+1}
\end{align}
Together
\begin{align}
    E\left(\hat{a}\right)=a+\frac{b-a}{N+1}
\end{align}
Similarly for $\hat{b}$:
\begin{align}
    F_{\hat{b}}\left(x\right)&=P\left(\hat{b}\leq x\right)
    \\&=\prod_n P\left(X_n\leq x\right)
    \\&=P^N\left(X\leq x\right)
    \\&=\left(\frac{x-a}{b-a}\right)^N
\end{align}
The density is
\begin{equation}
    \pdv{F_{\hat{b}}}{x}=\frac{N}{b-a}\left(\frac{x-a}{b-a}\right)^{N-1}
\end{equation}
The expectation value of $\hat{b}$ is
\begin{align}
    E(\hat{b})&=\int_{a}^{b}x\frac{N}{b-a}\left(\frac{x-a}{b-a}\right)^{N-1}\;dx
    \\&=\left[\left(\frac{x-a}{b-a}\right)^N x\right]_a^b-\int_{a}^{b}\left(\frac{x-a}{b-a}\right)^N\;dx
\end{align}
where
\begin{align}
    \left[\left(\frac{x-a}{b-a}\right)^N x\right]_a^b&=\left[\underbrace{\left(\frac{b-a}{b-a}\right)^N}_{=1}b-\underbrace{\left(\frac{a-a}{b-a}\right)^N}_{=0}a\right]=b
\end{align}
and
\begin{align}
    \int_{a}^{b}\left(\frac{x-a}{b-a}\right)^N\;dx&=\left[\frac{b-a}{N+1}\left(\frac{x-a}{b-a}\right)^{N+1}\right]_a^b
    \\&=\frac{b-a}{N+1}\left[\underbrace{\left(\frac{b-a}{b-a}\right)^{N+1}}_{=1}-\underbrace{\left(\frac{a-a}{b-a}\right)^{N+1}}_{=0}\right]
    \\&=\frac{b-a}{N+1}
\end{align}
Together
\begin{align}
    E(\hat{b})=b-\frac{b-a}{N+1}
\end{align}
\paragraph{Conclusion} Both estimators are biased, but asymptotically unbiased. This makes intuitivly sense.
We would like to correct the estimators $\hat{a}$ and $\hat{b}$.
\begin{align}
    \hat{a}_c &= \min_n\left\{X_n\right\}-\frac{b-a}{N+1}
    \\\hat{b}_c &= \max_n\left\{X_n\right\}+\frac{b-a}{N+1}
\end{align}
but $a$ and $b$ are not a priori known.
Note that
\begin{equation}
    \frac{E(\hat{a}+\hat{b})}{2}=\frac{E(\hat{a})+E(\hat{b})}{2}=\frac{a+b}{2}
\end{equation}
is an estimator for the mean and unbiased.